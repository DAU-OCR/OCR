
### **금일 작업 보고서 (2025-08-24)**

**1. 개요**

- **목표**: `re_250822.md` 리포트에 기반하여, `hidden_size`가 512로 상향된 최종 학습 스크립트(`train_v1_6_0_full_kor_hs512.py`)를 실행, '전체 가상 데이터셋'에 대한 학습을 개시하는 것.
- **결과**: 목표 달성 과정에서 **(1)스크립트 오류, (2)실행 환경(GPU) 문제, (3)모델 학습 실패**라는 3가지 주요 문제를 순차적으로 발견하고 해결함. 최종적으로 근본 원인이었던 **'불완전한 문자셋'**을 수정하여, 안정적인 재학습을 위한 모든 준비를 완료함.

**2. 주요 진행 상황**

**가. 학습 계획 확정 및 스크립트 오류 수정**

- `GEMINI.md`에 명시된 `train_v1_5_1.py` 실행 계획을 최신 리포트(`re_250822.md`)에 따라 `train_v1_6_0_full_kor_hs512.py`로 업데이트함.
- 스크립트 최초 실행 시, `AttributeError: module 'torch.cuda' has no attribute 'cuda_is_available'` 오류 발생.
- 원인이 `torch.cuda.is_available()` 함수의 오타임을 확인하고 즉시 코드를 수정함.

**나. GPU 인식 문제 해결**

- 스크립트 오류 수정 후에도, `Using device: cpu`로 실행되며 GPU를 활용하지 못하는 2차 문제 발생.
- **진단 과정**:
    1.  `nvidia-smi` 명령어로 NVIDIA 드라이버 및 GPU(RTX 4060)가 시스템에 정상 인식됨을 확인.
    2.  별도의 테스트 스크립트 실행 결과, `torch.cuda.is_available()`이 `True`로 반환됨.
    3.  위 결과를 통해, 사용자의 `(crnn_ocr)` Conda 가상 환경에 설치된 PyTorch와 시스템의 기본 Python 환경 간의 버전 충돌을 문제의 원인으로 특정함.
- **해결 조치**:
    - `crnn_ocr` 환경 내 기존 PyTorch를 `pip uninstall`로 완전히 제거.
    - `nvidia-smi`에서 확인된 드라이버(CUDA 13.0 호환)에 맞는 `torch==2.5.1+cu121` 버전을 `--index-url`을 통해 명시적으로 재설치함.
    - 조치 후 `Using device: cuda`로 정상 실행됨을 확인함.

**다. 시험 학습 및 실패 원인 심층 분석**

- GPU로 학습을 시작했으나, 검증 정확도가 약 31%에서 정체되어 47번째 에포크에서 `Early stopping`으로 중단됨.
- **1차 원인 분석 (치명적 결함)**:
    - 학습 로그의 샘플 예측(`[Sample] GT: 'ㅑ' -> Pred: ''`)을 분석한 결과, 모델이 **한글 자음/모음(자모) 단일 문자**를 전혀 학습하지 못함을 발견.
    - `train_v1_6_0_full_kor_hs512.py`의 `VIRTUAL_CHARSET` 변수에 완성형 한글, 영문, 숫자만 포함되어 있고 **자모(Jamo)가 누락**된 것을 확인. 이는 모델의 성능 한계를 야기하는 결정적 원인이었음.
- **2차 원인 분석 (사용자 지적 기반)**:
    - 사용자가 "드, 댜 같은 일반 문자도 정답이 안 나온다"고 지적.
    - 이를 통해, '자모 누락'이 단순히 해당 문자만 학습 못하는 것을 넘어, 존재하지 않는 문자를 처리하려는 과정에서 **모델의 전체적인 학습 안정성을 저해**하고 다른 모든 문자의 학습까지 방해했을 것이라는 가설을 수립함.

**3. 최종 조치 및 결과**

- **조치**: `train_v1_6_0_full_kor_hs512.py`의 문자셋 정의 코드를 수정하여, `JAMO_CHARS` 변수를 새로 추가하고 이를 `VIRTUAL_CHARSET`에 포함시킴. (이후 `train_v1_6_1_full_kor_hs512.py`로 파일명 변경)
- **결과**: 이제 스크립트는 완성형 한글, 자모, 영문, 숫자를 모두 포함하는 **완전한 문자셋**을 갖추게 됨. 이로써 이전 학습의 근본적인 문제를 해결하고, 모델의 잠재 성능을 온전히 평가할 수 있는 기반을 마련함.

**4. 다음 단계**

- 수정된 최종 스크립트를 실행하여, 완전한 문자셋 기반의 **베이스라인 성능을 재측정**하고, 그 결과에 따라 추가적인 하이퍼파라미터 튜닝 여부를 결정할 예정.

---

### **금일 작업 보고서 (2025-08-24) - 추가 분석 및 결론**

**1. 개요**

- **목표**: `train_v1_6_1` 스크립트 재학습 시 검증 정확도가 약 42%에서 정체되는 문제의 근본 원인 규명.
- **분석 전략**: **(1) 단순화 테스트**와 **(2) 데이터셋 심층 분석**이라는 두 가지 접근법을 병행하여 문제의 범위를 좁힘.
- **결과**: 모델 자체의 성능은 정상임을 입증했으며, 기존의 '데이터 불균형' 가설을 뒤집고 **'문자셋 간의 간섭 현상'**이라는 새로운 핵심 가설을 수립함.

**2. 분석 과정 및 상세 내용**

**가. 접근 1: 단순화 테스트 (모델 성능 검증)**

- **실행**: `train_v1_5_3_mini_kor_hs512.py` 스크립트를 사용하여, 문자셋이 훨씬 작은 'mini_kor' 데이터셋으로 동일한 CRNN 모델을 학습시킴.
- **결과**: 검증 정확도(Val Acc)가 **최고 96.61%**에 도달하는 매우 높은 성능을 기록함.
- **결론**: CRNN 모델 아키텍처 자체는 정상적으로 작동하며, 한정된 문자셋에 대해서는 충분히 높은 성능을 낼 수 있음을 명확히 **입증함.** 따라서 문제의 원인은 모델이 아닌 데이터에 있음을 확신.

**나. 접근 2: 전체 가상 데이터셋 심층 분석**

- **기존 가설**: '전체 가상 데이터셋'의 230개라는 방대한 문자 클래스 간에 심각한 수량 불균형이 존재하여, 소수 클래스의 학습이 제대로 이루어지지 않을 것이라 추측함.
- **실행**: 데이터셋의 문자 분포를 정확히 파악하기 위해, 115,000개의 라벨 파일을 모두 읽어 문자별 개수를 세는 `analyze_dataset.py` 스크립트를 작성하고 실행함.
- **결과**: 모든 예측을 뒤엎고, 230개의 모든 문자가 **정확히 500개씩 존재**하는 **완벽하게 균형 잡힌 데이터셋**임을 확인함.
- **결론**: 성능 저하의 원인은 **데이터 불균형이 아님**을 최종적으로 확인함.

**3. 종합 결론 및 새로운 가설**

- **종합 분석**: (가)에서 모델이 정상임을 확인했고, (나)에서 데이터 불균형이 원인이 아님을 확인했다. 이 두 가지 사실을 종합했을 때, 문제의 본질은 더 미묘한 곳에 있음을 알 수 있다.
- **새로운 핵심 가설: "문자셋 간의 간섭(Interference)"**
    - 현재 모델은 한글, 영문, 숫자, 기호라는, 특성이 매우 다른 여러 문자셋을 **동시에 학습**하고 있다.
    - 이 과정에서 'B'와 '비', '0'과 'ㅇ'처럼 시각적으로 유사한 다른 언어의 문자들을 구분하는 데 혼란을 겪고, 하나의 문자셋을 학습하면 다른 문자셋에 대한 판단 능력이 저하되는 **간섭 현상**이 발생하는 것으로 강력히 추정된다.
    - 이 간섭 현상이 모델의 학습을 불안정하게 만들어, 42%라는 성능의 벽을 넘지 못하게 하는 근본적인 원인으로 판단된다.

**4. 향후 계획 (사용자 요청으로 보류)**

- **목표**: "문자셋 간섭" 가설을 검증하고 해결.
- **실행 계획**: '한글 전용 데이터셋' (한글+숫자+기호)을 새로 생성하여, 간섭 요인(영문)을 제거한 상태에서 모델이 높은 성능을 달성하는지 확인한다.
- **상태**: 위 계획은 사용자의 요청에 따라 다음 작업으로 보류됨.
