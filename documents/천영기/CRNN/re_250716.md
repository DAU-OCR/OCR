# 가상 데이터셋 기반 OCR 모델 학습 파이프라인 구축 (2025-07-16)

## 1. 개요

실제 번호판 이미지 부족 문제를 해결하고, 모델의 문자 인식 성능을 강화하기 위해 대규모 가상 문자 데이터셋을 생성했다. 이 가상 데이터를 기반으로 CRNN 모델을 효과적으로 학습시키기 위한 새로운 파이프라인을 구축했다. 이 과정에는 가상 데이터 생성 스크립트 고도화, 검증 데이터 분리, 그리고 가상 데이터 전용 학습 스크립트 작성이 포함된다.

---

## 2. 주요 작업 내용

### 가. 가상 데이터 생성 스크립트 고도화 및 분리

- **포괄적 문자셋 구축**: `create_virtual_data.py` 스크립트의 문자셋을 대폭 확장했다. 기존의 제한된 문자셋에서 벗어나, 완성형 한글, 자음/모음(자모), 대소문자 영문, 숫자를 모두 포함하는 포괄적인 문자셋(`VIRTUAL_CHARSET`)을 정의했다. 이를 통해 모델이 다양한 형태의 문자를 학습할 수 있는 기반을 마련했다.

- **검증 데이터 생성 스크립트 분리**: 기존에는 단일 스크립트로 학습 데이터를 생성했으나, 모델 성능을 객관적으로 평가하기 위해 검증 데이터셋의 필요성이 대두되었다. 이에, 훈련용 데이터와는 별개로 검증용 데이터를 생성하는 `create_virtual_data_val.py` 스크립트를 신규 작성했다. 이를 통해 훈련과 검증 과정을 명확히 분리하여 모델의 일반화 성능을 보다 신뢰성 있게 측정할 수 있게 되었다.

### 나. 가상 데이터 전용 학습 파이프라인 신규 구축 (`train_v1_5_1.py`)

- **학습 스크립트 작성**: 생성된 대규모 가상 데이터를 활용하여 CRNN 모델을 학습시키기 위한 `train_v1_5_1.py`를 새로 작성했다. 이 스크립트는 `ocr/data/virtual_data`를 학습 데이터로, `ocr/data/virtual_val_data`를 검증 데이터로 사용하도록 경로를 설정했다.

- **확장된 문자셋 적용**: `LabelEncoder`가 가상 데이터 생성 시 사용된 포괄적인 문자셋(`VIRTUAL_CHARSET`)을 사용하도록 설정했다. 이를 통해 모델이 데이터셋에 포함된 모든 문자를 정확히 인코딩하고 학습할 수 있도록 파이프라인을 통일했다.

- **하이퍼파라미터 최적화**: 가상 데이터의 특성(단일 문자, 작은 이미지 크기)을 고려하여 학습 효율을 높이고자 하이퍼파라미터를 조정했다. 배치 크기를 128로 늘려 GPU 활용률을 높이고, 학습률을 0.001로 설정하는 등 가상 데이터 학습에 더 적합한 환경을 구성했다.

---

## 3. 기대 효과

- **모델 성능 향상**: 실제 데이터에서 얻기 힘든 다양한 형태의 문자 이미지를 대량으로 학습함으로써, OCR 모델의 전반적인 인식 정확도와 강건성(robustness)이 향상될 것으로 기대된다.
- **안정적인 학습 및 평가**: 훈련 데이터와 완전히 분리된 검증 데이터셋을 사용함으로써, 과적합(overfitting)을 방지하고 모델의 실제 성능을 더 정확하게 평가할 수 있는 안정적인 실험 환경이 구축되었다.
