### **주제: 검증 정확도와 실제 성능의 차이 발생 시 해결 전략**

**1. 문제 상황 정의**
- **현상**: 모델의 검증(Validation) 단계에서는 정확도가 94%로 매우 높게 나타나지만, 실제 데이터를 대상으로 테스트하면 정확도가 63%로 급락하는 문제.
- **용어**: 이를 "모델의 일반화 성능이 낮다" 또는 "과적합(Overfitting)되었다"고 정의함.

**2. 핵심 원인 진단**
- **가설**: 코드나 모델 구조의 문제라기보다는, **학습/검증 데이터와 실제 데이터 간의 분포 불일치(Distribution Mismatch)**가 주된 원인일 가능성이 높음.
- **상세 설명**: 모델이 깨끗하고 정제된 학습 데이터의 특정 패턴만 암기하여, 조명, 각도, 노이즈 등 다양한 변수가 존재하는 실제 데이터에는 제대로 대응하지 못하는 상태임.

**3. 추천 해결 전략: 데이터 중심 개선 (Data-Centric Improvement)**
- **방향**: 기존 학습 코드나 모델을 전면 수정하는 것은 비효율적. 대신, 모델이 배울 **데이터의 질을 높여** 현실의 다양성에 대응할 수 있도록 하는 것이 핵심.
- **전제**: 검증 정확도 94%는 현재 모델이 "정답을 학습할 능력"을 충분히 갖추고 있음을 의미하는 긍정적인 신호임.

**4. 단계별 실행 계획**
- **1단계: 실패 케이스 분석 (Error Analysis)**
    - 가장 중요한 단계. 성능이 낮게 나온 실제 데이터 중 **틀린 예측(Failure Case)들을 직접 관찰하고, 실패 원인을 유형별로 분류**함. (예: 빛 반사, 기울어짐, 특정 문자 인식 실패 등)
- **2단계: 데이터셋 강화 (Dataset Enhancement)**
    - **데이터 증강 (Data Augmentation)**: 1단계 분석 결과를 바탕으로, 모델이 취약한 유형의 데이터를 인위적으로 생성. 기존 학습 데이터에 회전, 밝기 조절, 노이즈 추가 등의 변형을 가하여 데이터의 다양성을 확보함.
    - **실제 데이터 편입**: 실패했던 실제 데이터의 일부를 학습 데이터셋에 추가하여, 모델이 실제 환경과 유사한 데이터를 직접 학습하도록 함.
- **3단계: 재학습 및 미세조정 (Re-training & Fine-tuning)**
    - 강화된 새 데이터셋을 사용하여 **기존 모델을 다시 학습**시킴. 이 과정에서 학습률(learning rate) 등 하이퍼파라미터를 미세하게 조정하여 성능을 최적화함.
- **4. 후처리 로직 구현 (Post-processing)**
    - 모델의 예측 결과를 번호판의 고정된 형식(예: '숫자 2개 + 한글 1개 + 숫자 4개')과 비교하여, 규칙에 어긋나는 부분을 자동으로 수정하는 로직을 추가함.

**5. 결론**
- 검증 성능과 실제 성능 간의 격차는 대부분 **데이터의 문제**에서 비롯된다.
- 따라서 **"실패 분석 → 데이터 강화 → 재학습"**의 반복적인 사이클을 통해 모델의 일반화 성능을 점진적으로 개선하는 것이 가장 효과적이고 표준적인 접근법이다.