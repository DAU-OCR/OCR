
# 데이터셋 검증 및 모델 학습 실패 원인 분석 (2025-08-21)

## 1. 개요

기존의 전체 한글 가상 데이터셋(`virtual_data`)으로 CRNN 모델을 학습했을 때, 손실(loss)이 전혀 감소하지 않는 **학습 실패 문제**가 발생했다. 오늘 작업의 목표는 이 문제의 근본 원인이 **데이터 자체의 결함**에 있는지, 혹은 **모델의 구조나 학습 방식**에 있는지 명확히 규명하는 것이었다.

---

## 2. 주요 진행 상황

### 가. 데이터셋 무결성 검증

- **가설**: 데이터 생성 과정의 오류로 인해 이미지나 라벨 파일이 손상되었거나, 개수가 맞지 않을 수 있다는 가설을 먼저 검증했다.
- **실행**: 데이터셋의 상태를 종합적으로 검증하는 `verify_dataset.py` 스크립트를 작성하여 실행했다.
- **결과**: 
  - 학습/검증 데이터 모두 이미지와 라벨의 **개수가 정확히 일치**함을 확인했다.
  - 모든 이미지와 라벨의 **파일명이 1:1로 매칭**됨을 확인했다.
  - 샘플 파일을 직접 열어본 결과, **이미지 손상이나 라벨의 인코딩 문제가 없음**을 확인했다.
- **결론**: 데이터셋 자체는 매우 건강하며, 학습 실패의 원인이 아님을 명확히 했다.

### 나. '미니 한글 데이터셋' 실험

- **가설**: 데이터가 정상이라면, 모델이 수천 개에 달하는 복잡한 한글 클래스를 한 번에 소화하지 못하는 것일 수 있다. 이를 확인하기 위해 모델이 학습할 수 있는 최소 단위를 테스트했다.
- **실행**:
  1. 문자셋을 **'초성(ㄱ-ㅎ) + 중성(ㅏ-ㅣ) + 숫자(0-9)' (총 36개 클래스)**로 대폭 축소한 '미니 한글 데이터셋'을 생성했다. (`create_virtual_data_mini_kor.py` 외 2개 스크립트 작성)
  2. 이 데이터셋을 사용하여 `train_v1_5_2_mini_kor_test.py` 스크립트로 모델 학습을 진행했다.

---

## 3. 실험 결과 및 분석

- **학습 시작 성공 (긍정적 신호)**: 이전과 달리, `Train Loss`가 첫 에포크에 6.71에서 3.67로 **크게 감소하며 학습이 시작되었음**을 확인했다. 이는 한글 문자 자체나 데이터 파이프라인의 문제가 아님을 증명하는 핵심적인 단서다.

- **학습 정체 및 실패 (문제점 확인)**: 하지만 `Val Acc` (검증 정확도)가 2.78% (무작위 추측 수준)에서 더 이상 개선되지 않고, 12 에포크만에 학습이 조기 종료되었다. 이는 모델이 **문자를 구별하는 능력까지는 학습하지 못했음**을 의미한다.

- **최종 결론**: 데이터에는 문제가 없었으며, 현재 **모델의 구조(`hidden_size=256`)와 하이퍼파라미터가 36개의 단순화된 문자셋조차 제대로 학습시키기에는 역부족**이라는 결론을 내렸다.

---

## 4. 다음 단계 (Next Steps)

- **목표**: 모델의 학습 능력을 강화하기 위해 **모델 아키텍처 및 하이퍼파라미터를 재조정**한다.

- **구체적인 계획**:
  1. **모델 용량 증대**: `hidden_size`를 256에서 **512**로 늘려 모델의 표현력을 높인다.
  2. **학습률 스케줄러 변경**: 수동적인 `ReduceLROnPlateau` 대신, 더 공격적인 `OneCycleLR`을 사용하여 학습 초기에 빠르게 최적점을 찾아가도록 유도한다.

- **실행할 작업**: 위 두 가지 변경 사항을 적용한 새로운 학습 스크립트(`train_v1_5_3_mini_kor_hs512.py`)를 작성하고, **'미니 한글 데이터셋'으로 다시 학습을 실행**하여 정확도가 유의미하게 상승하는지 확인한다.
