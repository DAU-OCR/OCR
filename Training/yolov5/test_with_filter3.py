import os
import cv2
import torch
import easyocr
from pathlib import Path
import numpy as np

# YOLOv5 ëª¨ë¸ ë¡œë“œ
model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/best.pt', force_reload=False)

# EasyOCR: ë¡œì»¬ ko.pth ì‚¬ìš©
reader = easyocr.Reader(['ko'], gpu=False,
                        model_storage_directory='custom_weights_easyOCR',
                        download_enabled=False)

# í´ë” ì„¤ì •
image_folder = 'images/korean'
save_crop_folder = 'cropped'
ocr_text_folder = 'ocr_results'
visual_folder = 'visualized'
os.makedirs(save_crop_folder, exist_ok=True)
os.makedirs(ocr_text_folder, exist_ok=True)
os.makedirs(visual_folder, exist_ok=True)

# í•„í„° ê¸°ì¤€
MIN_AREA = 2000
MIN_ASPECT_RATIO = 1.2
MIN_CONFIDENCE = 0.4

def preprocess_plate(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # âœ… ëŒ€ë¹„ í–¥ìƒ: CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)

    # âœ… ì„ ëª…ë„ í–¥ìƒ: Unsharp Mask
    gaussian = cv2.GaussianBlur(gray, (9, 9), 10.0)
    gray = cv2.addWeighted(gray, 1.5, gaussian, -0.5, 0)

    # âœ… ë…¸ì´ì¦ˆ ì œê±°: Bilateral Filter (ê°€ì¥ìë¦¬ ìœ ì§€)
    gray = cv2.bilateralFilter(gray, d=9, sigmaColor=75, sigmaSpace=75)

    return gray  # thresholdëŠ” ì ìš© X (easyOCR ì„±ëŠ¥ ì €í•˜)

# ì´ë¯¸ì§€ ë£¨í”„
for fname in os.listdir(image_folder):
    if not fname.lower().endswith(('.jpg', '.png', '.jpeg')):
        continue

    image_path = os.path.join(image_folder, fname)
    img = cv2.imread(image_path)
    if img is None:
        print(f"[ì˜¤ë¥˜] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {fname}")
        continue

    results = model(img)
    detections = results.xyxy[0]

    filtered = []
    for det in detections:
        x1, y1, x2, y2, conf, cls = det.tolist()
        w, h = x2 - x1, y2 - y1
        area = w * h
        aspect_ratio = w / h if h != 0 else 0

        if area >= MIN_AREA and aspect_ratio >= MIN_ASPECT_RATIO and conf >= MIN_CONFIDENCE:
            filtered.append((area, (int(x1), int(y1), int(x2), int(y2))))

    if not filtered:
        print(f"âŒ {fname}: ì¡°ê±´ì— ë§ëŠ” ë²ˆí˜¸íŒ ì—†ìŒ")
        continue

    # ê°€ì¥ í° ë°•ìŠ¤ ì„ íƒ
    filtered.sort(reverse=True)
    _, (x1, y1, x2, y2) = filtered[0]

    cropped = img[y1:y2, x1:x2]
    preprocessed = preprocess_plate(cropped)

    crop_fname = f"{Path(fname).stem}_plate.jpg"
    crop_path = os.path.join(save_crop_folder, crop_fname)
    cv2.imwrite(crop_path, cropped)

    # OCR ìˆ˜í–‰
    ocr_result = reader.readtext(preprocessed)
    txt_path = os.path.join(ocr_text_folder, f"{Path(fname).stem}_ocr.txt")

    print(f"\nğŸ” íŒŒì¼: {fname} | OCR ê²°ê³¼:")
    lines = []
    with open(txt_path, 'w', encoding='utf-8') as f:
        if ocr_result:
            for (_, text, conf) in ocr_result:
                line = f"{text} (ì‹ ë¢°ë„: {conf:.2f})"
                lines.append(line)
                print(f"â¡ï¸ {line}")
                f.write(line + '\n')
        else:
            print("âŒ ì¸ì‹ ì‹¤íŒ¨")
            f.write("âŒ ì¸ì‹ ì‹¤íŒ¨\n")

    # ì‹œê°í™”
    vis_img = img.copy()
    cv2.rectangle(vis_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    for i, line in enumerate(lines):
        text_y = y1 - 10 - i * 20
        if text_y < 0: text_y = y1 + 20 + i * 20
        cv2.putText(vis_img, line, (x1, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

    visual_path = os.path.join(visual_folder, f"{Path(fname).stem}_vis.jpg")
    cv2.imwrite(visual_path, vis_img)
