import sys
import os
import cv2
import torch
from pathlib import Path
import easyocr

# YOLOv5 ë£¨íŠ¸ ë””ë ‰í„°ë¦¬ ë“±ë¡
FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from models.common import DetectMultiBackend
from utils.dataloaders import LoadImages
from utils.general import non_max_suppression, scale_boxes, check_img_size, cv2
from utils.torch_utils import select_device

# ê²½ë¡œ ì„¤ì •
weights = 'weights/best.pt'
source = 'images/korean'
save_crop_dir = 'cropped'
save_txt_dir = 'ocr_results'
os.makedirs(save_crop_dir, exist_ok=True)
os.makedirs(save_txt_dir, exist_ok=True)

device = select_device('cpu')
model = DetectMultiBackend(weights, device=device)
stride, names, pt = model.stride, model.names, model.pt
imgsz = check_img_size(640, s=stride)

reader = easyocr.Reader(['ko'], gpu=False)
dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)

# ì¶”ë¡  ë£¨í”„
for path, img, im0s, vid_cap, s in dataset:
    img = torch.from_numpy(img).to(device)
    img = img.float() / 255.0
    if img.ndim == 3:
        img = img[None]

    pred = model(img, augment=False, visualize=False)
    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)

    p = Path(path)
    im0 = im0s.copy()

    for i, det in enumerate(pred):
        if len(det):
            det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], im0.shape).round()

            for j, (*xyxy, conf, cls) in enumerate(det):
                x1, y1, x2, y2 = map(int, xyxy)
                cropped = im0[y1:y2, x1:x2].copy()

                # OCR ìˆ˜í–‰
                ocr_result = reader.readtext(cropped)

                print(f"\nğŸ” íŒŒì¼: {p.name} | ë²ˆí˜¸íŒ {j + 1}")
                result_txt_path = os.path.join(save_txt_dir, f"{p.stem}_plate{j + 1}.txt")
                with open(result_txt_path, 'w', encoding='utf-8') as f:
                    if ocr_result:
                        for (bbox, text, conf_score) in ocr_result:
                            line = f"{text} (ì‹ ë¢°ë„: {conf_score:.2f})"
                            print(f"â¡ï¸ ì¸ì‹ ê²°ê³¼: {line}")
                            f.write(line + '\n')

                            # ë°•ìŠ¤ ì¢Œí‘œ ê·¸ë¦¬ê¸°
                            pts = [tuple(map(int, point)) for point in bbox]
                            for k in range(4):
                                cv2.line(cropped, pts[k], pts[(k + 1) % 4], (0, 255, 0), 2)
                            # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                            cv2.putText(cropped, text, pts[0], cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                    else:
                        print("âŒ ì¸ì‹ ì‹¤íŒ¨")
                        f.write("âŒ ì¸ì‹ ì‹¤íŒ¨\n")

                # Crop ì €ì¥ (ì‹œê°í™” í¬í•¨)
                crop_save_path = os.path.join(save_crop_dir, f"{p.stem}_plate{j + 1}.jpg")
                cv2.imwrite(crop_save_path, cropped)
